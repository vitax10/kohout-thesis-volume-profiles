{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f4ab8d9-d00f-4f0e-bc23-5918e10f83b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter-kohv04@vse.cz\n",
      "/home/jupyter-kohv04@vse.cz/kohv04/backtesting_final\n",
      "/home/jupyter-kohv04@vse.cz/kohv04/backtesting_final/simulation_results\n",
      "/home/jupyter-kohv04@vse.cz/kohv04/backtesting_final/metadata\n",
      "/home/jupyter-kohv04@vse.cz/kohv04/backtesting_final/metadata/all_regimes.csv\n",
      "/home/jupyter-kohv04@vse.cz/kohv04/backtesting_final/hypothesis_testing\n",
      "/home/jupyter-kohv04@vse.cz/kohv04/backtesting_final/hypothesis_testing/trade_level_regime_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# 1. DEFINING BASE DIRECTORY\n",
    "HOME_DIR = Path.home()\n",
    "BASE_DIR = HOME_DIR / \"kohv04\" / \"backtesting_final\"\n",
    "# 2. DEFINING DATA LOCATIONS (using os.path.join for robust path creation)\n",
    "SIMULATION_RESULTS_DIR = os.path.join(BASE_DIR, \"simulation_results\")\n",
    "METADATA_DIR = os.path.join(BASE_DIR, \"metadata\")\n",
    "REGIME_FILE = os.path.join(METADATA_DIR, \"all_regimes.csv\")\n",
    "\n",
    "# 3.OUTPUT DIRECTORY\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"hypothesis_testing\")\n",
    "AGGREGATED_TRADES_FILE = os.path.join(OUTPUT_DIR, \"trade_level_regime_analysis.csv\")\n",
    "HYPOTHESIS_RESULTS_FILE = os.path.join(OUTPUT_DIR, \"hypothesis_1.csv\")\n",
    "\n",
    "# 4. STRATEGY CATEGORIES FOR HYPOTHESIS TESTING\n",
    "STRATEGY_MAP = {\n",
    "    'breakout': [\n",
    "        'Baseline_Breakout',\n",
    "        'Volume-Enhanced_Breakout',\n",
    "        'Deep_Learning_Breakout'\n",
    "    ],\n",
    "    'mean_reversion': [\n",
    "        'Baseline_Bollinger_Bands',\n",
    "        'Volume-Enhanced_VWAP_Reversion',\n",
    "        'Deep_Learning_VWAP_Reversion'\n",
    "    ],\n",
    "    'momentum': [\n",
    "        'Baseline_Momentum',\n",
    "        'Volume-Enhanced_Momentum',\n",
    "        'Deep_Learning_Momentum'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(HOME_DIR)\n",
    "print(BASE_DIR)\n",
    "print(SIMULATION_RESULTS_DIR)\n",
    "print(METADATA_DIR)\n",
    "print(REGIME_FILE)\n",
    "print(OUTPUT_DIR)\n",
    "print(AGGREGATED_TRADES_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e733986-0ba5-481c-b3de-4aeba7509433",
   "metadata": {},
   "source": [
    "# Hypothesis 1 - Regime-Specific Performance \n",
    "Intraday trading strategies exhibit distinct performance profiles across market regimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "669092b3-6c21-46a8-a289-60c4342c308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_trade_data():\n",
    "    \"\"\"\n",
    "    Part 1: Aggregates all trades from all simulations and merges them with\n",
    "    daily market regime data. It also cleans the data for robustness.\n",
    "    \"\"\"\n",
    "    print(\"--- Part 1: Starting Data Aggregation ---\")\n",
    "    \n",
    "    if os.path.exists(AGGREGATED_TRADES_FILE):\n",
    "        print(f\"Aggregated file already exists at {AGGREGATED_TRADES_FILE}. Loading it.\")\n",
    "        try:\n",
    "            return pd.read_csv(AGGREGATED_TRADES_FILE)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load existing file, will re-aggregate. Error: {e}\")\n",
    "\n",
    "    try:\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "        print(f\"Output directory ensured at: {OUTPUT_DIR}\")\n",
    "    except Exception as e:\n",
    "        print(f\"FATAL ERROR: Could not create directory: {e}\")\n",
    "        return None\n",
    "\n",
    "    if not os.path.exists(REGIME_FILE):\n",
    "        print(f\"ERROR: Regime file not found at {REGIME_FILE}\")\n",
    "        return None\n",
    "\n",
    "    print(\"Loading regime data...\")\n",
    "    regime_df = pd.read_csv(REGIME_FILE)\n",
    "    regime_df['date'] = pd.to_datetime(regime_df['date']).dt.date\n",
    "    regime_df.set_index(['ticker', 'date'], inplace=True)\n",
    "    print(\"Regime data loaded successfully.\")\n",
    "\n",
    "    all_trades_list = []\n",
    "    \n",
    "    try:\n",
    "        with os.scandir(SIMULATION_RESULTS_DIR) as tickers:\n",
    "            for ticker_entry in tickers:\n",
    "                if ticker_entry.is_dir():\n",
    "                    ticker_name = ticker_entry.name\n",
    "                    ticker_path = ticker_entry.path\n",
    "                    with os.scandir(ticker_path) as strategies:\n",
    "                        for strategy_entry in strategies:\n",
    "                            if strategy_entry.is_dir():\n",
    "                                strategy_name = strategy_entry.name\n",
    "                                trades_file = os.path.join(strategy_entry.path, \"trades.csv\")\n",
    "                                if os.path.exists(trades_file):\n",
    "                                    try:\n",
    "                                        trades_df = pd.read_csv(trades_file)\n",
    "                                        if trades_df.empty: continue\n",
    "                                        trades_df['Ticker'] = ticker_name\n",
    "                                        trades_df['Strategy'] = strategy_name\n",
    "                                        trades_df['date'] = pd.to_datetime(trades_df['Entry Timestamp']).dt.date\n",
    "                                        merged_df = trades_df.reset_index().merge(\n",
    "                                            regime_df.reset_index(),\n",
    "                                            left_on=['Ticker', 'date'],\n",
    "                                            right_on=['ticker', 'date'],\n",
    "                                            how='left'\n",
    "                                        )\n",
    "                                        all_trades_list.append(merged_df)\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Could not process {trades_file}. Error: {e}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"FATAL ERROR: The directory {SIMULATION_RESULTS_DIR} was not found.\")\n",
    "        return None\n",
    "\n",
    "    if not all_trades_list:\n",
    "        print(\"ERROR: No trade data could be aggregated.\")\n",
    "        return None\n",
    "\n",
    "    print(\"\\nConcatenating all trades into a single DataFrame...\")\n",
    "    final_df = pd.concat(all_trades_list, ignore_index=True)\n",
    "\n",
    "    print(\"Cleaning data: Checking for infinite values in 'Return' column...\")\n",
    "    initial_rows = len(final_df)\n",
    "    final_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    final_df.dropna(subset=['Return'], inplace=True)\n",
    "    cleaned_rows = len(final_df)\n",
    "    print(f\"Removed {initial_rows - cleaned_rows} rows with invalid 'Return' values.\")\n",
    "\n",
    "    final_df.to_csv(AGGREGATED_TRADES_FILE, index=False)\n",
    "    print(f\"Success! Aggregated data saved to: {AGGREGATED_TRADES_FILE}\")\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def test_hypotheses(df):\n",
    "    \"\"\"\n",
    "    Part 2: Loads the aggregated data, runs robust statistical tests, and saves\n",
    "    the detailed results to a CSV file.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Part 2: Starting Hypothesis Testing ---\")\n",
    "\n",
    "    if df is None or df.empty:\n",
    "        print(\"ERROR: Input DataFrame is empty. Cannot run tests.\")\n",
    "        return\n",
    "\n",
    "    def get_category(strategy_name):\n",
    "        for category, names in STRATEGY_MAP.items():\n",
    "            if strategy_name in names:\n",
    "                return category\n",
    "        return 'other'\n",
    "    df['Strategy Category'] = df['Strategy'].apply(get_category)\n",
    "    \n",
    "    hypothesis_results = []\n",
    "\n",
    "    def run_ttest(h_id, description, group1, group2, alternative, group1_name, group2_name):\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Evaluating Hypothesis {h_id}: {description}\")\n",
    "        \n",
    "        group1_size = group1.count()\n",
    "        group2_size = group2.count()\n",
    "        print(f\"Sample size for Group 1 ('{group1_name}'): {group1_size}\")\n",
    "        print(f\"Sample size for Group 2 ('{group2_name}'): {group2_size}\")\n",
    "\n",
    "        if group1_size < 2 or group2_size < 2:\n",
    "            print(\"Result: INCONCLUSIVE. At least one group has fewer than 2 data points.\")\n",
    "            t_stat, p_value = np.nan, np.nan\n",
    "            is_significant = \"Inconclusive\"\n",
    "            conclusion = \"Test could not be performed due to insufficient data (< 2 trades) in one or both categories.\"\n",
    "        else:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "                t_stat, p_value = stats.ttest_ind(\n",
    "                    group1, group2, nan_policy='omit', equal_var=False, alternative=alternative\n",
    "                )\n",
    "\n",
    "            alpha = 0.05\n",
    "            if p_value < alpha:\n",
    "                is_significant = \"Yes\"\n",
    "                conclusion = f\"Data supports that mean return for '{group1_name}' is {'greater' if alternative=='greater' else 'less'} than for '{group2_name}'.\"\n",
    "                print(f\"Result: SIGNIFICANT (p < {alpha}). We reject the null hypothesis.\")\n",
    "            else:\n",
    "                is_significant = \"No\"\n",
    "                conclusion = \"Fail to reject the null hypothesis.\"\n",
    "                print(f\"Result: NOT SIGNIFICANT (p >= {alpha}). We fail to reject the null hypothesis.\")\n",
    "            print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "        hypothesis_results.append({\n",
    "            \"Hypothesis ID\": h_id,\n",
    "            \"Description\": description,\n",
    "            \"Group 1\": group1_name,\n",
    "            \"Group 1 Sample Size\": group1_size,\n",
    "            \"Group 2\": group2_name,\n",
    "            \"Group 2 Sample Size\": group2_size,\n",
    "            \"T-statistic\": t_stat,\n",
    "            \"P-value\": p_value,\n",
    "            \"Significant (alpha=0.05)\": is_significant,\n",
    "            \"Conclusion\": conclusion\n",
    "        })\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    # --- Running tests with fully corrected logic ---\n",
    "    breakout_df = df[df['Strategy Category'] == 'breakout']\n",
    "    meanrev_df = df[df['Strategy Category'] == 'mean_reversion']\n",
    "    momentum_df = df[df['Strategy Category'] == 'momentum']\n",
    "    \n",
    "    # H1a: Breakout strategies in medium/high vs. low volatility\n",
    "    run_ttest(\"H1a\", \"Breakout strategies perform better in medium/high volatility than in low volatility.\", \n",
    "              breakout_df[breakout_df['volatility_regime'].isin(['High', 'Medium'])]['Return'], \n",
    "              breakout_df[breakout_df['volatility_regime'] == 'Low']['Return'], \n",
    "              'greater', \"Breakout (Medium/High Vol)\", \"Breakout (Low Vol)\")\n",
    "\n",
    "    # H1b: Breakout strategies in trending vs. ranging markets\n",
    "    run_ttest(\"H1b\", \"Breakout strategies perform better in trending vs ranging markets.\", \n",
    "              breakout_df[breakout_df['trend_regime'].isin(['Uptrend', 'Downtrend'])]['Return'], \n",
    "              breakout_df[breakout_df['trend_regime'] == 'Range']['Return'], \n",
    "              'greater', \"Breakout (Trending)\", \"Breakout (Ranging)\")\n",
    "\n",
    "    # H1c: Mean-reversion strategies in low/medium vs. high volatility\n",
    "    run_ttest(\"H1c\", \"Mean-reversion strategies perform better in low/medium volatility than in high volatility.\", \n",
    "              meanrev_df[meanrev_df['volatility_regime'].isin(['Low', 'Medium'])]['Return'], \n",
    "              meanrev_df[meanrev_df['volatility_regime'] == 'High']['Return'], \n",
    "              'greater', \"Mean-Reversion (Low/Medium Vol)\", \"Mean-Reversion (High Vol)\")\n",
    "\n",
    "    # H1d: Mean-reversion strategies in uptrending vs. ranging markets\n",
    "    run_ttest(\"H1d\", \"Mean-reversion strategies perform worse in uptrends than in ranging markets.\", \n",
    "              meanrev_df[meanrev_df['trend_regime'] == 'Uptrend']['Return'], \n",
    "              meanrev_df[meanrev_df['trend_regime'] == 'Range']['Return'], \n",
    "              'less', \"Mean-Reversion (Uptrend)\", \"Mean-Reversion (Ranging)\")\n",
    "\n",
    "    # H1e: Momentum strategies in trending/high-volatility vs. ranging/low-volatility markets\n",
    "    run_ttest(\"H1e\", \"Momentum strategies perform better in trending/high-volatility markets than in low-vol/ranging.\", \n",
    "              momentum_df[(momentum_df['trend_regime'].isin(['Uptrend', 'Downtrend'])) & \n",
    "                          (momentum_df['volatility_regime'] == 'High')]['Return'], \n",
    "              momentum_df[(momentum_df['trend_regime'] == 'Range') & \n",
    "                          (momentum_df['volatility_regime'] == 'Low')]['Return'], \n",
    "              'greater', \"Momentum (Trend/High-Vol)\", \"Momentum (Range/Low-Vol)\")\n",
    "\n",
    "    # Results to CSV\n",
    "    results_df = pd.DataFrame(hypothesis_results)\n",
    "    column_order = [\n",
    "        \"Hypothesis ID\", \"Description\", \"Group 1\", \"Group 1 Sample Size\", \n",
    "        \"Group 2\", \"Group 2 Sample Size\", \"T-statistic\", \"P-value\", \n",
    "        \"Significant (alpha=0.05)\", \"Conclusion\"\n",
    "    ]\n",
    "    results_df = results_df[column_order]\n",
    "    results_df.to_csv(HYPOTHESIS_RESULTS_FILE, index=False)\n",
    "    print(f\"\\nHypothesis testing results successfully saved to: {HYPOTHESIS_RESULTS_FILE}\")\n",
    "    print(\"\\n--- Final Results Summary ---\")\n",
    "    print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc5759c7-94e7-4182-967b-89121a0f53ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Part 1: Starting Data Aggregation ---\n",
      "Aggregated file already exists at /home/jupyter-kohv04@vse.cz/kohv04/backtesting_final/hypothesis_testing/trade_level_regime_analysis.csv. Loading it.\n",
      "\n",
      "--- Part 2: Starting Hypothesis Testing ---\n",
      "--------------------------------------------------\n",
      "Evaluating Hypothesis H1a: Breakout strategies perform better in medium/high volatility than in low volatility.\n",
      "Sample size for Group 1 ('Breakout (Medium/High Vol)'): 21267\n",
      "Sample size for Group 2 ('Breakout (Low Vol)'): 4650\n",
      "Result: NOT SIGNIFICANT (p >= 0.05). We fail to reject the null hypothesis.\n",
      "T-statistic: 0.6910, P-value: 0.2448\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Evaluating Hypothesis H1b: Breakout strategies perform better in trending vs ranging markets.\n",
      "Sample size for Group 1 ('Breakout (Trending)'): 6837\n",
      "Sample size for Group 2 ('Breakout (Ranging)'): 19080\n",
      "Result: NOT SIGNIFICANT (p >= 0.05). We fail to reject the null hypothesis.\n",
      "T-statistic: -0.5495, P-value: 0.7086\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Evaluating Hypothesis H1c: Mean-reversion strategies perform better in low/medium volatility than in high volatility.\n",
      "Sample size for Group 1 ('Mean-Reversion (Low/Medium Vol)'): 34442\n",
      "Sample size for Group 2 ('Mean-Reversion (High Vol)'): 9435\n",
      "Result: SIGNIFICANT (p < 0.05). We reject the null hypothesis.\n",
      "T-statistic: 2.5534, P-value: 0.0053\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Evaluating Hypothesis H1d: Mean-reversion strategies perform worse in uptrends than in ranging markets.\n",
      "Sample size for Group 1 ('Mean-Reversion (Uptrend)'): 6944\n",
      "Sample size for Group 2 ('Mean-Reversion (Ranging)'): 32277\n",
      "Result: SIGNIFICANT (p < 0.05). We reject the null hypothesis.\n",
      "T-statistic: -2.0085, P-value: 0.0223\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Evaluating Hypothesis H1e: Momentum strategies perform better in trending/high-volatility markets than in low-vol/ranging.\n",
      "Sample size for Group 1 ('Momentum (Trend/High-Vol)'): 705\n",
      "Sample size for Group 2 ('Momentum (Range/Low-Vol)'): 1092\n",
      "Result: SIGNIFICANT (p < 0.05). We reject the null hypothesis.\n",
      "T-statistic: 1.9692, P-value: 0.0246\n",
      "--------------------------------------------------\n",
      "\n",
      "Hypothesis testing results successfully saved to: /home/jupyter-kohv04@vse.cz/kohv04/backtesting_final/hypothesis_testing/hypothesis_1.csv\n",
      "\n",
      "--- Final Results Summary ---\n",
      "  Hypothesis ID                                        Description  \\\n",
      "0           H1a  Breakout strategies perform better in medium/h...   \n",
      "1           H1b  Breakout strategies perform better in trending...   \n",
      "2           H1c  Mean-reversion strategies perform better in lo...   \n",
      "3           H1d  Mean-reversion strategies perform worse in upt...   \n",
      "4           H1e  Momentum strategies perform better in trending...   \n",
      "\n",
      "                           Group 1  Group 1 Sample Size  \\\n",
      "0       Breakout (Medium/High Vol)                21267   \n",
      "1              Breakout (Trending)                 6837   \n",
      "2  Mean-Reversion (Low/Medium Vol)                34442   \n",
      "3         Mean-Reversion (Uptrend)                 6944   \n",
      "4        Momentum (Trend/High-Vol)                  705   \n",
      "\n",
      "                     Group 2  Group 2 Sample Size  T-statistic   P-value  \\\n",
      "0         Breakout (Low Vol)                 4650     0.691012  0.244790   \n",
      "1         Breakout (Ranging)                19080    -0.549458  0.708649   \n",
      "2  Mean-Reversion (High Vol)                 9435     2.553407  0.005339   \n",
      "3   Mean-Reversion (Ranging)                32277    -2.008465  0.022310   \n",
      "4   Momentum (Range/Low-Vol)                 1092     1.969217  0.024559   \n",
      "\n",
      "  Significant (alpha=0.05)                                         Conclusion  \n",
      "0                       No                Fail to reject the null hypothesis.  \n",
      "1                       No                Fail to reject the null hypothesis.  \n",
      "2                      Yes  Data supports that mean return for 'Mean-Rever...  \n",
      "3                      Yes  Data supports that mean return for 'Mean-Rever...  \n",
      "4                      Yes  Data supports that mean return for 'Momentum (...  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    aggregated_df = aggregate_trade_data()\n",
    "    if aggregated_df is not None:\n",
    "        test_hypotheses(aggregated_df)\n",
    "    else:\n",
    "        print(\"\\nProcess failed. Cannot run hypothesis tests.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff83e48-1ef9-4c9f-906a-192421a00b5b",
   "metadata": {},
   "source": [
    "# Hypothesis 2 - Volume as a Confirmation Signal\n",
    "Incorporating volume-based parameters improves the profitability of intraday strategies compared to price-only baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a616345-4fba-4f62-a336-daae5bacee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. BASE DIRECTORY\n",
    "HOME_DIR = Path.home()\n",
    "BASE_DIR = HOME_DIR / \"kohv04\" / \"backtesting_final\"\n",
    "\n",
    "# 2. DATA LOCATIONS\n",
    "SIMULATION_RESULTS_DIR = os.path.join(BASE_DIR, \"simulation_results\")\n",
    "# The summary file is the key data source\n",
    "SUMMARY_FILE = os.path.join(SIMULATION_RESULTS_DIR, \"simulation_summary.csv\")\n",
    "\n",
    "# 3. OUTPUT DIRECTORY\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"hypothesis_testing\")\n",
    "HYPOTHESIS_RESULTS_FILE = os.path.join(OUTPUT_DIR, \"hypothesis_2.csv\")\n",
    "\n",
    "# 4. STRATEGY PAIRS TO COMPARE\n",
    "STRATEGY_PAIRS = {\n",
    "    \"Baseline Breakout\": \"Volume-Enhanced Breakout\",\n",
    "    \"Baseline Momentum\": \"Volume-Enhanced Momentum\",\n",
    "    \"Baseline Bollinger Bands\": \"Volume-Enhanced VWAP Reversion\"\n",
    "}\n",
    "\n",
    "# 5. METRICS TO TEST\n",
    "# H1 direction: 'greater' means we expect the volume version to be higher.\n",
    "#              'less' means we expect the volume version to be lower.\n",
    "METRICS_TO_TEST = [\n",
    "    (\"Sharpe Ratio\", 'greater', \"Sharpe Ratio\"),\n",
    "    (\"Profit Factor\", 'greater', \"Profit Factor\"),\n",
    "    (\"Max Drawdown [%]\", 'less', \"Max Drawdown\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cbefd5b-6d0c-4fb2-963f-b17f7a5f4565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hypothesis_2():\n",
    "    \"\"\"\n",
    "    Evaluates Hypothesis 2 by performing paired t-tests between baseline\n",
    "    and volume-enhanced strategies with robust data checking.\n",
    "    \"\"\"\n",
    "    print(\"--- Part 1: Loading and Preparing Data ---\")\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "        print(f\"Output directory ensured at: {OUTPUT_DIR}\")\n",
    "    except Exception as e:\n",
    "        print(f\"FATAL ERROR: Could not create directory: {e}\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(SUMMARY_FILE):\n",
    "        print(f\"FATAL ERROR: The summary file was not found at {SUMMARY_FILE}\")\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        df = pd.read_csv(SUMMARY_FILE)\n",
    "        print(\"Successfully loaded simulation_summary.csv\")\n",
    "    except Exception as e:\n",
    "        print(f\"FATAL ERROR: Could not read summary file. Error: {e}\")\n",
    "        return\n",
    "\n",
    "    # Upfront Data Cleaning\n",
    "    print(\"\\nCleaning and validating data types...\")\n",
    "    for col, _, _ in METRICS_TO_TEST:\n",
    "        if col in df.columns:\n",
    "            # Forcing column to be numeric, coercing any non-numeric values into NaN\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        else:\n",
    "            print(f\"Warning: Metric column '{col}' not found in the summary file.\")\n",
    "    # Replacing any infinite values with NaN\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    print(\"Data cleaning complete.\")\n",
    "\n",
    "    print(\"\\n--- Part 2: Starting Paired T-Tests for Hypothesis 2 ---\")\n",
    "    \n",
    "    all_results = []\n",
    "\n",
    "    for baseline_strat, volume_strat in STRATEGY_PAIRS.items():\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Comparing: '{baseline_strat}' vs. '{volume_strat}'\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        pair_df = df[df['Strategy'].isin([baseline_strat, volume_strat])]\n",
    "        \n",
    "        for col_name, alternative, metric_name in METRICS_TO_TEST:\n",
    "            \n",
    "            try:\n",
    "                pivoted = pair_df.pivot_table(index='Ticker', columns='Strategy', values=col_name)\n",
    "                pivoted.dropna(inplace=True)\n",
    "                \n",
    "                group1 = pivoted[baseline_strat]\n",
    "                group2 = pivoted[volume_strat]\n",
    "                \n",
    "                sample_size = len(pivoted)\n",
    "                \n",
    "                print(f\"\\n-- Testing Metric: {metric_name} --\")\n",
    "                print(f\"Paired sample size (tickers with both results): {sample_size}\")\n",
    "                \n",
    "                differences = group2 - group1\n",
    "                print(f\"\\nDifferences (Volume - Baseline) summary:\\n{differences.describe()}\")\n",
    "                \n",
    "                std_diff = differences.std()\n",
    "                if std_diff == 0:\n",
    "                    print(\"\\nCRITICAL WARNING: The standard deviation of the differences is zero. T-test is invalid.\")\n",
    "                print(\"--------------------\\n\")\n",
    "\n",
    "                if sample_size < 2 or std_diff == 0:\n",
    "                    print(\"Result: INCONCLUSIVE. Insufficient data or zero variance in differences.\")\n",
    "                    t_stat, p_value = np.nan, np.nan\n",
    "                    is_significant = \"Inconclusive\"\n",
    "                    conclusion = \"Test invalid due to insufficient samples or zero variance in paired differences.\"\n",
    "                else:\n",
    "                    t_stat, p_value = stats.ttest_rel(group2, group1, alternative=alternative, nan_policy='omit')\n",
    "\n",
    "                    alpha = 0.05\n",
    "                    if p_value < alpha:\n",
    "                        is_significant = \"Yes\"\n",
    "                        conclusion = f\"Data supports that '{volume_strat}' has a significantly {'better' if alternative != 'less' else 'lower'} {metric_name}.\"\n",
    "                        print(f\"Result: SIGNIFICANT (p < {alpha}). We reject the null hypothesis.\")\n",
    "                    else:\n",
    "                        is_significant = \"No\"\n",
    "                        conclusion = f\"Fail to reject the null hypothesis for {metric_name}.\"\n",
    "                        print(f\"Result: NOT SIGNIFICANT (p >= {alpha}). We fail to reject the null hypothesis.\")\n",
    "                    \n",
    "                    print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "            except KeyError:\n",
    "                print(f\"\\n-- Testing Metric: {metric_name} --\")\n",
    "                print(f\"ERROR: Could not find data for one of the strategies. Skipping.\")\n",
    "                t_stat, p_value, sample_size = np.nan, np.nan, 0\n",
    "                is_significant = \"Error\"\n",
    "                conclusion = \"Data missing for one or both strategies in the pair.\"\n",
    "            \n",
    "            all_results.append({\n",
    "                \"Comparison\": f\"{baseline_strat} vs. {volume_strat}\",\n",
    "                \"Metric\": metric_name,\n",
    "                \"H1 Direction\": f\"Volume-Enhanced {('>' if alternative == 'greater' else '<')} Baseline\",\n",
    "                \"Paired Samples (Tickers)\": sample_size,\n",
    "                \"T-statistic\": t_stat,\n",
    "                \"P-value\": p_value,\n",
    "                \"Significant (alpha=0.05)\": is_significant,\n",
    "                \"Conclusion\": conclusion\n",
    "            })\n",
    "\n",
    "    print(\"\\n--- Part 3: Saving Hypothesis 2 Results ---\")\n",
    "    if not all_results:\n",
    "        print(\"No results were generated. Cannot save file.\")\n",
    "        return\n",
    "        \n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    column_order = [\n",
    "        \"Comparison\", \"Metric\", \"H1 Direction\", \"Paired Samples (Tickers)\",\n",
    "        \"T-statistic\", \"P-value\", \"Significant (alpha=0.05)\", \"Conclusion\"\n",
    "    ]\n",
    "    results_df = results_df[column_order]\n",
    "\n",
    "    results_df.to_csv(HYPOTHESIS_RESULTS_FILE, index=False)\n",
    "    print(f\"\\nHypothesis 2 testing results successfully saved to: {HYPOTHESIS_RESULTS_FILE}\")\n",
    "    print(\"\\n--- Final Results Summary ---\")\n",
    "    print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88bf2817-fa35-4736-a3a7-7da609cdbb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Part 1: Loading and Preparing Data ---\n",
      "Output directory ensured at: /home/jupyter-kohv04@vse.cz/kohv04/backtesting_final/hypothesis_testing\n",
      "Successfully loaded simulation_summary.csv\n",
      "\n",
      "Cleaning and validating data types...\n",
      "Data cleaning complete.\n",
      "\n",
      "--- Part 2: Starting Paired T-Tests for Hypothesis 2 ---\n",
      "============================================================\n",
      "Comparing: 'Baseline Breakout' vs. 'Volume-Enhanced Breakout'\n",
      "============================================================\n",
      "\n",
      "-- Testing Metric: Sharpe Ratio --\n",
      "Paired sample size (tickers with both results): 100\n",
      "\n",
      "Differences (Volume - Baseline) summary:\n",
      "count    100.000000\n",
      "mean       0.789416\n",
      "std        8.686696\n",
      "min      -17.895328\n",
      "25%       -5.568098\n",
      "50%        0.388636\n",
      "75%        5.883303\n",
      "max       21.452769\n",
      "dtype: float64\n",
      "--------------------\n",
      "\n",
      "Result: NOT SIGNIFICANT (p >= 0.05). We fail to reject the null hypothesis.\n",
      "T-statistic: 0.9088, P-value: 0.1828\n",
      "\n",
      "-- Testing Metric: Profit Factor --\n",
      "Paired sample size (tickers with both results): 99\n",
      "\n",
      "Differences (Volume - Baseline) summary:\n",
      "count    99.000000\n",
      "mean     -0.039895\n",
      "std       0.438805\n",
      "min      -1.142115\n",
      "25%      -0.329075\n",
      "50%      -0.092868\n",
      "75%       0.227797\n",
      "max       1.492600\n",
      "dtype: float64\n",
      "--------------------\n",
      "\n",
      "Result: NOT SIGNIFICANT (p >= 0.05). We fail to reject the null hypothesis.\n",
      "T-statistic: -0.9046, P-value: 0.8161\n",
      "\n",
      "-- Testing Metric: Max Drawdown --\n",
      "Paired sample size (tickers with both results): 100\n",
      "\n",
      "Differences (Volume - Baseline) summary:\n",
      "count    100.000000\n",
      "mean      -1.266748\n",
      "std        1.206066\n",
      "min       -5.436410\n",
      "25%       -1.939007\n",
      "50%       -1.030700\n",
      "75%       -0.432693\n",
      "max        0.905332\n",
      "dtype: float64\n",
      "--------------------\n",
      "\n",
      "Result: SIGNIFICANT (p < 0.05). We reject the null hypothesis.\n",
      "T-statistic: -10.5031, P-value: 0.0000\n",
      "============================================================\n",
      "Comparing: 'Baseline Momentum' vs. 'Volume-Enhanced Momentum'\n",
      "============================================================\n",
      "\n",
      "-- Testing Metric: Sharpe Ratio --\n",
      "Paired sample size (tickers with both results): 101\n",
      "\n",
      "Differences (Volume - Baseline) summary:\n",
      "count    101.000000\n",
      "mean      -2.991777\n",
      "std        7.945255\n",
      "min      -21.453284\n",
      "25%       -8.132408\n",
      "50%       -3.550591\n",
      "75%        1.364332\n",
      "max       17.615585\n",
      "dtype: float64\n",
      "--------------------\n",
      "\n",
      "Result: NOT SIGNIFICANT (p >= 0.05). We fail to reject the null hypothesis.\n",
      "T-statistic: -3.7843, P-value: 0.9999\n",
      "\n",
      "-- Testing Metric: Profit Factor --\n",
      "Paired sample size (tickers with both results): 101\n",
      "\n",
      "Differences (Volume - Baseline) summary:\n",
      "count    101.000000\n",
      "mean      -0.150320\n",
      "std        0.850932\n",
      "min       -3.964421\n",
      "25%       -0.405800\n",
      "50%       -0.090038\n",
      "75%        0.215900\n",
      "max        3.636900\n",
      "dtype: float64\n",
      "--------------------\n",
      "\n",
      "Result: NOT SIGNIFICANT (p >= 0.05). We fail to reject the null hypothesis.\n",
      "T-statistic: -1.7753, P-value: 0.9606\n",
      "\n",
      "-- Testing Metric: Max Drawdown --\n",
      "Paired sample size (tickers with both results): 101\n",
      "\n",
      "Differences (Volume - Baseline) summary:\n",
      "count    101.000000\n",
      "mean      -1.104743\n",
      "std        1.070440\n",
      "min       -4.192545\n",
      "25%       -1.795716\n",
      "50%       -0.928744\n",
      "75%       -0.368525\n",
      "max        1.428296\n",
      "dtype: float64\n",
      "--------------------\n",
      "\n",
      "Result: SIGNIFICANT (p < 0.05). We reject the null hypothesis.\n",
      "T-statistic: -10.3719, P-value: 0.0000\n",
      "============================================================\n",
      "Comparing: 'Baseline Bollinger Bands' vs. 'Volume-Enhanced VWAP Reversion'\n",
      "============================================================\n",
      "\n",
      "-- Testing Metric: Sharpe Ratio --\n",
      "Paired sample size (tickers with both results): 101\n",
      "\n",
      "Differences (Volume - Baseline) summary:\n",
      "count    101.000000\n",
      "mean      -6.213357\n",
      "std        9.098907\n",
      "min      -35.903918\n",
      "25%      -11.983154\n",
      "50%       -6.408550\n",
      "75%       -1.100476\n",
      "max       23.132098\n",
      "dtype: float64\n",
      "--------------------\n",
      "\n",
      "Result: NOT SIGNIFICANT (p >= 0.05). We fail to reject the null hypothesis.\n",
      "T-statistic: -6.8627, P-value: 1.0000\n",
      "\n",
      "-- Testing Metric: Profit Factor --\n",
      "Paired sample size (tickers with both results): 101\n",
      "\n",
      "Differences (Volume - Baseline) summary:\n",
      "count    101.000000\n",
      "mean      -0.278017\n",
      "std        0.884519\n",
      "min       -2.884073\n",
      "25%       -0.767350\n",
      "50%       -0.352869\n",
      "75%        0.088008\n",
      "max        3.073138\n",
      "dtype: float64\n",
      "--------------------\n",
      "\n",
      "Result: NOT SIGNIFICANT (p >= 0.05). We fail to reject the null hypothesis.\n",
      "T-statistic: -3.1588, P-value: 0.9990\n",
      "\n",
      "-- Testing Metric: Max Drawdown --\n",
      "Paired sample size (tickers with both results): 101\n",
      "\n",
      "Differences (Volume - Baseline) summary:\n",
      "count    101.000000\n",
      "mean      -0.197694\n",
      "std        0.604201\n",
      "min       -1.976056\n",
      "25%       -0.462853\n",
      "50%       -0.191123\n",
      "75%        0.038708\n",
      "max        2.232880\n",
      "dtype: float64\n",
      "--------------------\n",
      "\n",
      "Result: SIGNIFICANT (p < 0.05). We reject the null hypothesis.\n",
      "T-statistic: -3.2883, P-value: 0.0007\n",
      "\n",
      "--- Part 3: Saving Hypothesis 2 Results ---\n",
      "\n",
      "Hypothesis 2 testing results successfully saved to: /home/jupyter-kohv04@vse.cz/kohv04/backtesting_final/hypothesis_testing/hypothesis_2.csv\n",
      "\n",
      "--- Final Results Summary ---\n",
      "                                          Comparison         Metric  \\\n",
      "0     Baseline Breakout vs. Volume-Enhanced Breakout   Sharpe Ratio   \n",
      "1     Baseline Breakout vs. Volume-Enhanced Breakout  Profit Factor   \n",
      "2     Baseline Breakout vs. Volume-Enhanced Breakout   Max Drawdown   \n",
      "3     Baseline Momentum vs. Volume-Enhanced Momentum   Sharpe Ratio   \n",
      "4     Baseline Momentum vs. Volume-Enhanced Momentum  Profit Factor   \n",
      "5     Baseline Momentum vs. Volume-Enhanced Momentum   Max Drawdown   \n",
      "6  Baseline Bollinger Bands vs. Volume-Enhanced V...   Sharpe Ratio   \n",
      "7  Baseline Bollinger Bands vs. Volume-Enhanced V...  Profit Factor   \n",
      "8  Baseline Bollinger Bands vs. Volume-Enhanced V...   Max Drawdown   \n",
      "\n",
      "                 H1 Direction  Paired Samples (Tickers)  T-statistic  \\\n",
      "0  Volume-Enhanced > Baseline                       100     0.908764   \n",
      "1  Volume-Enhanced > Baseline                        99    -0.904624   \n",
      "2  Volume-Enhanced < Baseline                       100   -10.503136   \n",
      "3  Volume-Enhanced > Baseline                       101    -3.784269   \n",
      "4  Volume-Enhanced > Baseline                       101    -1.775344   \n",
      "5  Volume-Enhanced < Baseline                       101   -10.371931   \n",
      "6  Volume-Enhanced > Baseline                       101    -6.862743   \n",
      "7  Volume-Enhanced > Baseline                       101    -3.158817   \n",
      "8  Volume-Enhanced < Baseline                       101    -3.288312   \n",
      "\n",
      "        P-value Significant (alpha=0.05)  \\\n",
      "0  1.828409e-01                       No   \n",
      "1  8.160586e-01                       No   \n",
      "2  4.380616e-18                      Yes   \n",
      "3  9.998685e-01                       No   \n",
      "4  9.605583e-01                       No   \n",
      "5  7.580980e-18                      Yes   \n",
      "6  1.000000e+00                       No   \n",
      "7  9.989523e-01                       No   \n",
      "8  6.959047e-04                      Yes   \n",
      "\n",
      "                                          Conclusion  \n",
      "0  Fail to reject the null hypothesis for Sharpe ...  \n",
      "1  Fail to reject the null hypothesis for Profit ...  \n",
      "2  Data supports that 'Volume-Enhanced Breakout' ...  \n",
      "3  Fail to reject the null hypothesis for Sharpe ...  \n",
      "4  Fail to reject the null hypothesis for Profit ...  \n",
      "5  Data supports that 'Volume-Enhanced Momentum' ...  \n",
      "6  Fail to reject the null hypothesis for Sharpe ...  \n",
      "7  Fail to reject the null hypothesis for Profit ...  \n",
      "8  Data supports that 'Volume-Enhanced VWAP Rever...  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    test_hypothesis_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e1d569-5616-4468-9947-6c6e11feba87",
   "metadata": {},
   "source": [
    "# Hypothesis 3 - Transformer-Based Volume Prediction\n",
    "Augmenting strategies with transformer-based forecasted short-term volume predictions increases performance,\n",
    "achieving improved metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69f9a0f5-88b2-4eb9-a6d2-c640f1baf560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. BASE DIRECTORY\n",
    "HOME_DIR = Path.home()\n",
    "BASE_DIR = HOME_DIR / \"kohv04\" / \"backtesting_final\"\n",
    "\n",
    "# 2. DATA LOCATIONS\n",
    "SIMULATION_RESULTS_DIR = os.path.join(BASE_DIR, \"simulation_results\")\n",
    "SUMMARY_FILE = os.path.join(SIMULATION_RESULTS_DIR, \"simulation_summary.csv\")\n",
    "\n",
    "# 3. OUTPUT DIRECTORY\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"hypothesis_testing\")\n",
    "HYPOTHESIS_RESULTS_FILE = os.path.join(OUTPUT_DIR, \"hypothesis_3.csv\")\n",
    "\n",
    "# 4. STRATEGY PAIRS TO COMPARE FOR H3\n",
    "STRATEGY_PAIRS = {\n",
    "    \"Volume-Enhanced Breakout\": \"Deep Learning Breakout\",\n",
    "    \"Volume-Enhanced Momentum\": \"Deep Learning Momentum\",\n",
    "    \"Volume-Enhanced VWAP Reversion\": \"Deep Learning VWAP Reversion\"\n",
    "}\n",
    "\n",
    "# 5. METRICS TO TEST\n",
    "METRICS_TO_TEST = [\n",
    "    (\"Sharpe Ratio\", 'greater', \"Sharpe Ratio\"),\n",
    "    (\"Profit Factor\", 'greater', \"Profit Factor\"),\n",
    "    (\"Max Drawdown [%]\", 'less', \"Max Drawdown\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fd1ade8-dd0f-4e90-b4d3-c469ebb31f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hypothesis_3():\n",
    "    \"\"\"\n",
    "    Evaluates Hypothesis 3 by performing paired t-tests between\n",
    "    Volume-Enhanced and Deep Learning (Transformer) strategies.\n",
    "    \"\"\"\n",
    "    print(\"--- Part 1: Loading and Preparing Data ---\")\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "        print(f\"Output directory ensured at: {OUTPUT_DIR}\")\n",
    "    except Exception as e:\n",
    "        print(f\"FATAL ERROR: Could not create directory: {e}\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(SUMMARY_FILE):\n",
    "        print(f\"FATAL ERROR: The summary file was not found at {SUMMARY_FILE}\")\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        df = pd.read_csv(SUMMARY_FILE)\n",
    "        print(\"Successfully loaded simulation_summary.csv\")\n",
    "    except Exception as e:\n",
    "        print(f\"FATAL ERROR: Could not read summary file. Error: {e}\")\n",
    "        return\n",
    "\n",
    "    # Upfront Data Cleaning\n",
    "    print(\"\\nCleaning and validating data types...\")\n",
    "    for col, _, _ in METRICS_TO_TEST:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        else:\n",
    "            print(f\"Warning: Metric column '{col}' not found in the summary file.\")\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    print(\"Data cleaning complete.\")\n",
    "\n",
    "    print(\"\\n--- Part 2: Starting Paired T-Tests for Hypothesis 3 ---\")\n",
    "    \n",
    "    all_results = []\n",
    "\n",
    "    for volume_strat, dl_strat in STRATEGY_PAIRS.items():\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Comparing: '{volume_strat}' vs. '{dl_strat}'\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        pair_df = df[df['Strategy'].isin([volume_strat, dl_strat])]\n",
    "        \n",
    "        for col_name, alternative, metric_name in METRICS_TO_TEST:\n",
    "            \n",
    "            try:\n",
    "                pivoted = pair_df.pivot_table(index='Ticker', columns='Strategy', values=col_name)\n",
    "                pivoted.dropna(inplace=True)\n",
    "                \n",
    "                group1 = pivoted[volume_strat]\n",
    "                group2 = pivoted[dl_strat]\n",
    "                \n",
    "                sample_size = len(pivoted)\n",
    "                \n",
    "                print(f\"\\n-- Testing Metric: {metric_name} --\")\n",
    "                print(f\"Paired sample size (tickers with both results): {sample_size}\")\n",
    "\n",
    "                if sample_size < 2:\n",
    "                    is_significant = \"Inconclusive\"\n",
    "                    conclusion = \"Test could not be performed due to insufficient paired data.\"\n",
    "                    t_stat, p_value = np.nan, np.nan\n",
    "                else:\n",
    "                    t_stat, p_value = stats.ttest_rel(group2, group1, alternative=alternative, nan_policy='omit')\n",
    "                    alpha = 0.05\n",
    "                    if p_value < alpha:\n",
    "                        is_significant = \"Yes\"\n",
    "                        conclusion = f\"Data supports that '{dl_strat}' has a significantly {'better' if alternative != 'less' else 'lower'} {metric_name}.\"\n",
    "                    else:\n",
    "                        is_significant = \"No\"\n",
    "                        conclusion = f\"Fail to reject the null hypothesis for {metric_name}.\"\n",
    "                    \n",
    "                    print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "            except KeyError as e:\n",
    "                print(f\"ERROR: Could not find strategy column: {e}. Skipping.\")\n",
    "                t_stat, p_value, sample_size = np.nan, np.nan, 0\n",
    "                is_significant = \"Error\"\n",
    "                conclusion = f\"Data missing for one or both strategies in the pair: {e}\"\n",
    "            \n",
    "            all_results.append({\n",
    "                \"Comparison\": f\"{volume_strat} vs. {dl_strat}\",\n",
    "                \"Metric\": metric_name,\n",
    "                \"H1 Direction\": f\"Deep Learning {('>' if alternative == 'greater' else '<')} Volume-Enhanced\",\n",
    "                \"Paired Samples (Tickers)\": sample_size,\n",
    "                \"T-statistic\": t_stat,\n",
    "                \"P-value\": p_value,\n",
    "                \"Significant (alpha=0.05)\": is_significant,\n",
    "                \"Conclusion\": conclusion\n",
    "            })\n",
    "\n",
    "    # Saving Results\n",
    "    print(\"\\n--- Part 3: Saving Hypothesis 3 Results ---\")\n",
    "    if not all_results:\n",
    "        print(\"No results were generated. Cannot save file.\")\n",
    "        return\n",
    "        \n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    column_order = [\n",
    "        \"Comparison\", \"Metric\", \"H1 Direction\", \"Paired Samples (Tickers)\",\n",
    "        \"T-statistic\", \"P-value\", \"Significant (alpha=0.05)\", \"Conclusion\"\n",
    "    ]\n",
    "    results_df = results_df[column_order]\n",
    "\n",
    "    results_df.to_csv(HYPOTHESIS_RESULTS_FILE, index=False)\n",
    "    print(f\"\\nHypothesis 3 testing results successfully saved to: {HYPOTHESIS_RESULTS_FILE}\")\n",
    "    print(\"\\n--- Final Results Summary ---\")\n",
    "    print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4608cc88-0e59-4118-85cd-b95e205bec82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Part 1: Loading and Preparing Data ---\n",
      "Output directory ensured at: /home/jupyter-kohv04@vse.cz/kohv04/backtesting_final/hypothesis_testing\n",
      "Successfully loaded simulation_summary.csv\n",
      "\n",
      "Cleaning and validating data types...\n",
      "Data cleaning complete.\n",
      "\n",
      "--- Part 2: Starting Paired T-Tests for Hypothesis 3 ---\n",
      "============================================================\n",
      "Comparing: 'Volume-Enhanced Breakout' vs. 'Deep Learning Breakout'\n",
      "============================================================\n",
      "\n",
      "-- Testing Metric: Sharpe Ratio --\n",
      "Paired sample size (tickers with both results): 100\n",
      "T-statistic: -3.4948, P-value: 0.9996\n",
      "\n",
      "-- Testing Metric: Profit Factor --\n",
      "Paired sample size (tickers with both results): 99\n",
      "T-statistic: 0.8192, P-value: 0.2073\n",
      "\n",
      "-- Testing Metric: Max Drawdown --\n",
      "Paired sample size (tickers with both results): 100\n",
      "T-statistic: 7.6788, P-value: 1.0000\n",
      "============================================================\n",
      "Comparing: 'Volume-Enhanced Momentum' vs. 'Deep Learning Momentum'\n",
      "============================================================\n",
      "\n",
      "-- Testing Metric: Sharpe Ratio --\n",
      "Paired sample size (tickers with both results): 101\n",
      "T-statistic: 0.2923, P-value: 0.3853\n",
      "\n",
      "-- Testing Metric: Profit Factor --\n",
      "Paired sample size (tickers with both results): 101\n",
      "T-statistic: 0.0754, P-value: 0.4700\n",
      "\n",
      "-- Testing Metric: Max Drawdown --\n",
      "Paired sample size (tickers with both results): 101\n",
      "T-statistic: -1.4619, P-value: 0.0735\n",
      "============================================================\n",
      "Comparing: 'Volume-Enhanced VWAP Reversion' vs. 'Deep Learning VWAP Reversion'\n",
      "============================================================\n",
      "\n",
      "-- Testing Metric: Sharpe Ratio --\n",
      "Paired sample size (tickers with both results): 101\n",
      "T-statistic: 0.4085, P-value: 0.3419\n",
      "\n",
      "-- Testing Metric: Profit Factor --\n",
      "Paired sample size (tickers with both results): 101\n",
      "T-statistic: -0.8768, P-value: 0.8087\n",
      "\n",
      "-- Testing Metric: Max Drawdown --\n",
      "Paired sample size (tickers with both results): 101\n",
      "T-statistic: 8.2450, P-value: 1.0000\n",
      "\n",
      "--- Part 3: Saving Hypothesis 3 Results ---\n",
      "\n",
      "Hypothesis 3 testing results successfully saved to: /home/jupyter-kohv04@vse.cz/kohv04/backtesting_final/hypothesis_testing/hypothesis_3.csv\n",
      "\n",
      "--- Final Results Summary ---\n",
      "                                          Comparison         Metric  \\\n",
      "0  Volume-Enhanced Breakout vs. Deep Learning Bre...   Sharpe Ratio   \n",
      "1  Volume-Enhanced Breakout vs. Deep Learning Bre...  Profit Factor   \n",
      "2  Volume-Enhanced Breakout vs. Deep Learning Bre...   Max Drawdown   \n",
      "3  Volume-Enhanced Momentum vs. Deep Learning Mom...   Sharpe Ratio   \n",
      "4  Volume-Enhanced Momentum vs. Deep Learning Mom...  Profit Factor   \n",
      "5  Volume-Enhanced Momentum vs. Deep Learning Mom...   Max Drawdown   \n",
      "6  Volume-Enhanced VWAP Reversion vs. Deep Learni...   Sharpe Ratio   \n",
      "7  Volume-Enhanced VWAP Reversion vs. Deep Learni...  Profit Factor   \n",
      "8  Volume-Enhanced VWAP Reversion vs. Deep Learni...   Max Drawdown   \n",
      "\n",
      "                      H1 Direction  Paired Samples (Tickers)  T-statistic  \\\n",
      "0  Deep Learning > Volume-Enhanced                       100    -3.494758   \n",
      "1  Deep Learning > Volume-Enhanced                        99     0.819160   \n",
      "2  Deep Learning < Volume-Enhanced                       100     7.678774   \n",
      "3  Deep Learning > Volume-Enhanced                       101     0.292326   \n",
      "4  Deep Learning > Volume-Enhanced                       101     0.075375   \n",
      "5  Deep Learning < Volume-Enhanced                       101    -1.461893   \n",
      "6  Deep Learning > Volume-Enhanced                       101     0.408532   \n",
      "7  Deep Learning > Volume-Enhanced                       101    -0.876840   \n",
      "8  Deep Learning < Volume-Enhanced                       101     8.245014   \n",
      "\n",
      "    P-value Significant (alpha=0.05)  \\\n",
      "0  0.999644                       No   \n",
      "1  0.207342                       No   \n",
      "2  1.000000                       No   \n",
      "3  0.385321                       No   \n",
      "4  0.470034                       No   \n",
      "5  0.073453                       No   \n",
      "6  0.341878                       No   \n",
      "7  0.808662                       No   \n",
      "8  1.000000                       No   \n",
      "\n",
      "                                          Conclusion  \n",
      "0  Fail to reject the null hypothesis for Sharpe ...  \n",
      "1  Fail to reject the null hypothesis for Profit ...  \n",
      "2  Fail to reject the null hypothesis for Max Dra...  \n",
      "3  Fail to reject the null hypothesis for Sharpe ...  \n",
      "4  Fail to reject the null hypothesis for Profit ...  \n",
      "5  Fail to reject the null hypothesis for Max Dra...  \n",
      "6  Fail to reject the null hypothesis for Sharpe ...  \n",
      "7  Fail to reject the null hypothesis for Profit ...  \n",
      "8  Fail to reject the null hypothesis for Max Dra...  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    test_hypothesis_3()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
